"""
Exemple d'utilisation de la gestion d'historique de conversation
avec LlamaIndex RAG Pipeline.
"""

from .semantic_pipeline import SemanticRAGPipelineFactory


def example_conversation_management():
    """Exemple complet de gestion d'historique de conversation"""

    # Cr√©er le pipeline
    pipeline = SemanticRAGPipelineFactory.create_semantic_pipeline()

    print("=== Exemple de Gestion d'Historique de Conversation ===\n")

    # === SC√âNARIO 1: Nouvelle conversation ===
    print("1. üÜï D√©marrage d'une nouvelle conversation")
    conv_id = "conv_project_discussion_001"
    pipeline.start_new_conversation(conv_id)

    # Premi√®re question
    answer1, sources1 = pipeline.process_query(
        query="Qui travaille sur le projet Isschat?", user_id="user123", conversation_id=conv_id, verbose=True
    )
    print("Q1: Qui travaille sur le projet Isschat?")
    print(f"R1: {answer1[:100]}...")
    print(f"Memory: {pipeline.get_memory_summary()}\n")

    # Question de suivi (avec contexte)
    answer2, sources2 = pipeline.process_query(
        query="Quelles sont leurs responsabilit√©s?", user_id="user123", conversation_id=conv_id, verbose=True
    )
    print("Q2: Quelles sont leurs responsabilit√©s?")
    print(f"R2: {answer2[:100]}...")
    print(f"Memory: {pipeline.get_memory_summary()}\n")

    # === SC√âNARIO 2: Interruption puis reprise ===
    print("2. üíæ Interruption de session (simulation red√©marrage)")

    # Cr√©er un nouveau pipeline (simulation red√©marrage)
    pipeline_new_session = SemanticRAGPipelineFactory.create_semantic_pipeline()

    print("3. üîÑ Reprise de conversation existante")
    # Reprendre la conversation pr√©c√©dente
    success = pipeline_new_session.continue_conversation(conv_id, user_id="user123")
    print(f"Historique charg√©: {success}")
    print(f"Memory apr√®s reprise: {pipeline_new_session.get_memory_summary()}\n")

    # Question utilisant le contexte charg√©
    answer3, sources3 = pipeline_new_session.process_query(
        query="Et Vincent, que fait-il exactement?", user_id="user123", conversation_id=conv_id, verbose=True
    )
    print("Q3: Et Vincent, que fait-il exactement?")
    print(f"R3: {answer3[:100]}...")
    print(f"Memory: {pipeline_new_session.get_memory_summary()}\n")

    # === SC√âNARIO 3: Changement de conversation ===
    print("4. üîÄ Changement vers une autre conversation")
    conv_id_2 = "conv_technical_support_002"

    answer4, sources4 = pipeline_new_session.process_query(
        query="Comment installer Isschat?",
        user_id="user123",
        conversation_id=conv_id_2,  # Nouvelle conversation
        verbose=True,
    )
    print("Q4 (nouvelle conv): Comment installer Isschat?")
    print(f"R4: {answer4[:100]}...")
    print(f"Memory: {pipeline_new_session.get_memory_summary()}\n")

    # === SC√âNARIO 4: Retour √† la premi√®re conversation ===
    print("5. ‚Ü©Ô∏è Retour √† la premi√®re conversation")
    answer5, sources5 = pipeline_new_session.process_query(
        query="Peux-tu me rappeler l'√©quipe du projet?",
        user_id="user123",
        conversation_id=conv_id,  # Retour √† la premi√®re conv
        verbose=True,
    )
    print("Q5 (retour conv 1): Peux-tu me rappeler l'√©quipe du projet?")
    print(f"R5: {answer5[:100]}...")
    print(f"Memory: {pipeline_new_session.get_memory_summary()}\n")

    # === STATISTIQUES FINALES ===
    print("6. üìä Statistiques du pipeline")
    stats = pipeline_new_session.get_stats()
    print(f"Pipeline Type: {stats['type']}")
    print(f"Memory Management: {stats['conversation_management']}")
    print(f"Adaptive Memory: {stats['adaptive_memory']}")


if __name__ == "__main__":
    example_conversation_management()
